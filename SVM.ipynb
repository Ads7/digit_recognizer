{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aman/Workspace/digit_recognizer\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /Users/aman/Workspace/digit_recognizer/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /Users/aman/Workspace/digit_recognizer/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /Users/aman/Workspace/digit_recognizer/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /Users/aman/Workspace/digit_recognizer/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(cwd+\"/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAJAMwQ0AyRDcAJDMfwFhTX+bEqVjSAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112414910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "class DigitData(object):\n",
    "    # Step 1 - Define our data\n",
    "    mnist = input_data.read_data_sets(CWD + \"/data/\", one_hot=True)\n",
    "    classses = [0,1,2,3,4,5,6,7,8,9]\n",
    "    # todo remove limit\n",
    "    Xtrn, Ytrn = np.array(mnist.train.images[:50]), np.array(mnist.train.labels[:50])\n",
    "    Xtest, Ytest = np.array(mnist.test.images), np.array(mnist.test.labels)\n",
    "X = DigitData().Xtest[1].reshape([28, 28])\n",
    "plt.gray()\n",
    "plt.imshow(X)\n",
    "\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM for digit recognition \n",
    "# Used for classification, outlier detection, regression\n",
    "# Usually discriminative classification  \n",
    "# Projects digit + emotion classification\n",
    "\n",
    "# Good for small data set\n",
    "\n",
    "# Donald Knuth:  “Premature optimization is root to all evil”\n",
    "# maximising space between classes the line drawn callled hyperplane\n",
    "# hyperlane is n-1 dimension \n",
    "\n",
    "#  linear vs Non linear\n",
    "# nonlinear-> kernel trick\n",
    "#  hinge loss max margin\n",
    "# reguarlizer(1/number of epochs) is tuner if too high overfit  too low underfilt\n",
    "# optimizer -> gradient decent\n",
    "# mis and classification conditions\n",
    "# learning rate for convergence\n",
    "\n",
    "# Pros and Cons associated with SVM\n",
    "\n",
    "# Pros:\n",
    "# It works really well with clear margin of separation\n",
    "# It is effective in high dimensional spaces.\n",
    "# It is effective in cases where number of dimensions is greater than the number of samples.\n",
    "# It uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "# Cons:\n",
    "# It doesn’t perform well, when we have large data set because the required training time is higher\n",
    "# It also doesn’t perform very well, when the data set has more noise i.e. target classes are overlapping\n",
    "# SVM doesn’t directly provide probability estimates, these are calculated using an expensive five-fold cross-validation. It is related SVC method of Python scikit-learn library.\n",
    "import numpy as np\n",
    "from matplotlib import plyplot as plt\n",
    "%mathplotlib inline\n",
    "\n",
    "X=np.array([-2,-4,-1]  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
